# SJU 20/5/20

## ZAD 1

Wzór na wykładnicze uśrednianie
$S_{n+1} = \alpha T_{n} + (1-\alpha)S_{n}$
$S_{n}$ - średnie obciążenie
$T_{n}$ - obciążenie przy n-tym wywołaniu


Nasze $\alpha$ - cexp
:::spoiler [cexp](http://bxr.su/FreeBSD/sys/kern/kern_synch.c#cexp)
```C=86
/*
 * Constants for averages over 1, 5, and 15 minutes
 * when sampling at 5 second intervals.
 */
static fixpt_t cexp[3] = {
    0.9200444146293232 * FSCALE,    /* exp(-1/12) */
    0.9834714538216174 * FSCALE,    /* exp(-1/60) */
    0.9944598480048967 * FSCALE,    /* exp(-1/180) */
};
```
:::

:::spoiler [loadav](http://bxr.su/FreeBSD/sys/kern/kern_synch.c#loadav)
sched_load <- przyjrzeć się
```C=604
/*
 * Compute a tenex style load average of a quantity on
 * 1, 5 and 15 minute intervals.
 */
static void
loadav(void *arg)
{
    int i, nrun;
    struct loadavg *avg;

    nrun = sched_load();
    avg = &averunnable;

    for (i = 0; i < 3; i++)
        avg->ldavg[i] = (cexp[i] * avg->ldavg[i] +
            nrun * FSCALE * (FSCALE - cexp[i])) >> FSHIFT;

    /*
     * Schedule the next update to occur after 5 seconds, but add a
     * random variation to avoid synchronisation with processes that
     * run at regular intervals.
     */
    callout_reset_sbt(&loadav_callout,
        SBT_1US * (4000000 + (int)(random() % 2000001)), SBT_1US,
        loadav, NULL, C_DIRECT_EXEC | C_PREL(32));
}
```
:::
Nasz wzór
$S_{n+1} = \frac{(S_{n} * \alpha + T_{n} * 2^{8} * (2^{8} - \alpha))}{2^{11}}$

## ZAD 2
Algorytm planisty długoterminowego zapewnia nam dobry czas reakcji na interaktywne zadania oraz zapewnia, że niskopriorytetowe zadania nie będą głodzone. Własności algorytmu:
* Wielopoziomowo/informacyjny (multilevel feedack) round-robin dla każdej kolejki priorytetowej
* Jeśli proces nie blokuje lub? (powinno być i) nie wykona się w przeciągu 1s zostaje wywłaszczony.
* Priorytet jest obliczany na podstawie typu procesu i historii wykonywania co 1 sekudne.
  * $CPU_{j}(i) = \frac{CPU_{j}(i-1)}{2}$
    $P_{j}(i) = Base_{j} + \frac{CPU_{j}(i)}{2} + nice_{j}$
      * $CPU_{j}(i)$ - zużycie procesora przez proces j prz interwał i
        $P_{j}(i)$ - priorytet procesu j na początku interwału i, niższy wartość oznacza wyższy priorytet
        $Base_{j}$ - piorytet bazowy procesu j
        $nice_{j}$ - kontrolowane przez użytkownika
* Wartości CPU i nice są ograniczone, aby zapewnić, że priorytet zadania nie wyjdzie poza ramy, które są narzucone przez priorytet bazowy.
* Ramy priorytetu są używane, aby zoptymalizować dostęp do urządzeń blokowych (urządzeń wejścia/wyjścia) i pozwoleniu systemowi odpowiadać szybko na syscall'e.

## ZAD 3
#### Niedostatki planisty O(1)
Słabe liczenie interaktywności.

#### Implementacja sprawiedliwego szeregowania
Zaimplementowano drzewo czerwono-czarne, na które jest indeksowane po vruntime.

#### W jaki sposób algorytm CFS wybiera kolejne zadanie do uruchomienia?
Z drzewa wybiera zadanie z najmniejszym vruntimem.

#### W jaki sposób nalicza wirtualny czas wykonania «vruntime», aby wymusić sprawiedliwy przydział czasu procesora?
Jest on naliczany poprzez dodawanie execution time.


## ZAD 4
Stopień interaktywności pomaga nam określić czy wątek jest interaktywny, a co za tym idzie taki wątek jest traktowany priorytetowo - dostaje większy priorytet niż zwykłe procesy. Widać to w [sched_priority](http://bxr.su/FreeBSD/sys/kern/sched_ule.c#sched_priority).
#### Wzór na stopień interaktywności
:::spoiler [sched_interact_score](http://bxr.su/FreeBSD/sys/kern/sched_ule.c#sched_interact_score)
```C
static int
sched_interact_score(struct thread *td)
{
    struct td_sched *ts;
    int div;

    ts = td_get_sched(td);
    
    if (sched_interact <= SCHED_INTERACT_HALF &&
        ts->ts_runtime >= ts->ts_slptime)
            return (SCHED_INTERACT_HALF);

    if (ts->ts_runtime > ts->ts_slptime) {
        div = max(1, ts->ts_runtime / SCHED_INTERACT_HALF);
        return (SCHED_INTERACT_HALF +
            (SCHED_INTERACT_HALF - (ts->ts_slptime / div)));
    }
    if (ts->ts_slptime > ts->ts_runtime) {
        div = max(1, ts->ts_slptime / SCHED_INTERACT_HALF);
        return (ts->ts_runtime / div);
    }
    /* runtime == slptime */
    if (ts->ts_runtime)
        return (SCHED_INTERACT_HALF);

    return (0);

}
```
:::
Jeśli czas snu jest większy niż czas działania
$$Scale  (T_{r} / T_{s})$$
Jeśli czas działania jest większy niż czas snu (jedynie wtedy kiedy próg bycia wątkiem interaktywnym > Scale)
$$Scale (2 - T_{s}/T_{r}) $$
#### Aktualizacja trzymania informacji o czasie przebiegu procesu
::: spoiler [sched_interact_update](http://bxr.su/FreeBSD/sys/kern/sched_ule.c#sched_interact_update)
```C
/*
 * This routine enforces a maximum limit on the amount of scheduling history
 * kept.  It is called after either the slptime or runtime is adjusted.  This
 * function is ugly due to integer math.
 */
static void
sched_interact_update(struct thread *td)
{
    struct td_sched *ts;
    u_int sum;

    ts = td_get_sched(td);
    sum = ts->ts_runtime + ts->ts_slptime;
    if (sum < SCHED_SLP_RUN_MAX)
        return;
    /*
     * This only happens from two places:
     * 1) We have added an unusual amount of run time from fork_exit.
     * 2) We have added an unusual amount of sleep time from sched_sleep().
     */
    if (sum > SCHED_SLP_RUN_MAX * 2) {
        if (ts->ts_runtime > ts->ts_slptime) {
            ts->ts_runtime = SCHED_SLP_RUN_MAX;
            ts->ts_slptime = 1;
        } else {
            ts->ts_slptime = SCHED_SLP_RUN_MAX;
            ts->ts_runtime = 1;
        }
        return;
    }
    /*
     * If we have exceeded by more than 1/5th then the algorithm below
     * will not bring us back into range.  Dividing by two here forces
     * us into the range of [4/5 * SCHED_INTERACT_MAX, SCHED_INTERACT_MAX]
     */
    if (sum > (SCHED_SLP_RUN_MAX / 5) * 6) {
        ts->ts_runtime /= 2;
        ts->ts_slptime /= 2;
        return;
    }
    ts->ts_runtime = (ts->ts_runtime / 5) * 4;
    ts->ts_slptime = (ts->ts_slptime / 5) * 4;
}
```
:::
Głównym zadaniem update jest umożliwienie liczenie priorytetu za pomocą tego jak się program zachowywał w przeszłości, a dokładnie na aktualizowaniu czasu ile zadanie spało/pracowało w przeczłości. Funkcja stara się, aby suma czasów była od 0 do SCHED_SLP_RUN_MAX.
Mamy 3 warianty:
1. Suma jest bardzo duża - dwa razy większa od SCHED_SLP_RUN_MAX
    * Większy czas ustawiamy na SCHED_SLP_RUN_MAX, a mniejszy na 1
2. Suma jest większa niż $\frac{6}{5}$ * SCHED_SLP_RUN_MA wtedy dzielimy czasy na dwa (umożliwi to nam powrót do porządanego przedziału)
3. Wpp mnożymy czasy razy $\frac{4}{5}$


## ZAD 5

Nasze zadania dzielimy na interaktywne i inne, interaktywne maja wiekszy priorytet oraz ich priorytet jest wprostproporcjonalny do tego jak bardzo interkatywne są. Za to inne zadania maja bazowy priorytet + estymowany(czasami jesli wiemy jak bardzo bedziemy korzystac z proc) + nice.
::: spoiler [sched_priority](http://bxr.su/FreeBSD/sys/kern/sched_ule.c#sched_priority)
```C
static void
sched_priority(struct thread *td)
{
    int score;
    int pri;

    if (PRI_BASE(td->td_pri_class) != PRI_TIMESHARE)
        return;
    /*
     * If the score is interactive we place the thread in the realtime
     * queue with a priority that is less than kernel and interrupt
     * priorities.  These threads are not subject to nice restrictions.
     *
     * Scores greater than this are placed on the normal timeshare queue
     * where the priority is partially decided by the most recent cpu
     * utilization and the rest is decided by nice value.
     *
     * The nice value of the process has a linear effect on the calculated
     * score.  Negative nice values make it easier for a thread to be
     * considered interactive.
     */
    score = imax(0, sched_interact_score(td) + td->td_proc->p_nice);
    if (score < sched_interact) {
        pri = PRI_MIN_INTERACT;
        pri += ((PRI_MAX_INTERACT - PRI_MIN_INTERACT + 1) /
            sched_interact) * score;
    } else {
        pri = SCHED_PRI_MIN;
        if (td_get_sched(td)->ts_ticks)
            pri += min(SCHED_PRI_TICKS(td_get_sched(td)),
                SCHED_PRI_RANGE - 1);
        pri += SCHED_PRI_NICE(td->td_proc->p_nice);
    }
    sched_user_prio(td, pri);

    return;
}
```
:::
#### Dlaczego zadania z podziałem czasu dodajemy do kolejki przy pomocy runq_add_pri zamiast «runq_add», a usuwamy przy pomocy runq_choose_from zamiast «runq_choose»?
Wynika to z zakresu priorytetów dla wątków z podziałem czasu.

## ZAD 6
### Algotytm wyznaczania odpowiedniego procesora
1. Wątki związane z tym CPU zostawiamy
2. Spawdzamy czy wątek już nie jest uruchomiony
3. Jeśli jesteśmy wątkiem przerwania
    1. I na procesorze jest wątkek idle to uruchom się na tym procesorze
    2. Przejdź do punktu 5
4. Jeśli możemy uruchomić na procesorze, z którym mamy affinity i jest on jałowy to uruchom na nim
5. Określamy ostatnią grupę CPU najbliższe w topologii
6. Postaraj się zabrać z najmniejszym obciążeniem i idle
7. Wpp postaraj się zabrać najmniej obciążony, na który możemy "uruchomić" teraz
8. Wpp znajdź najmniej obciążony
9. Porównaj załadowany CPU z obecnym
::: spoiler
```C [sched_pickcpu](http://bxr.su/FreeBSD/sys/kern/sched_ule.c#sched_pickcpu)
static int
sched_pickcpu(struct thread *td, int flags)
{
    struct cpu_group *cg, *ccg;
    struct td_sched *ts;
    struct tdq *tdq;
    cpuset_t mask;
    int cpu, pri, self, intr;

    self = PCPU_GET(cpuid);
    ts = td_get_sched(td);
    
    if (smp_started == 0)
        return (self);
    /*
     * Don't migrate a running thread from sched_switch().
     */
    if ((flags & SRQ_OURSELF) || !THREAD_CAN_MIGRATE(td))
        return (ts->ts_cpu);
    /*
     * Prefer to run interrupt threads on the processors that generate
     * the interrupt.
     */
    if (td->td_priority <= PRI_MAX_ITHD && THREAD_CAN_SCHED(td, self) &&
        curthread->td_intr_nesting_level) {
        tdq = TDQ_SELF();
        if (tdq->tdq_lowpri >= PRI_MIN_IDLE) {
            SCHED_STAT_INC(pickcpu_idle_affinity);
            return (self);
        }
        ts->ts_cpu = self;
        intr = 1;
        cg = tdq->tdq_cg;
        goto llc;
    } else {
        intr = 0;
        tdq = TDQ_CPU(ts->ts_cpu);
        cg = tdq->tdq_cg;
    }
    /*
     * If the thread can run on the last cpu and the affinity has not
     * expired and it is idle, run it there.
     */
    if (THREAD_CAN_SCHED(td, ts->ts_cpu) &&
        tdq->tdq_lowpri >= PRI_MIN_IDLE &&
        SCHED_AFFINITY(ts, CG_SHARE_L2)) {
        if (cg->cg_flags & CG_FLAG_THREAD) {
            /* Check all SMT threads for being idle. */
            for (cpu = CPU_FFS(&cg->cg_mask) - 1; ; cpu++) {
                if (CPU_ISSET(cpu, &cg->cg_mask) &&
                    TDQ_CPU(cpu)->tdq_lowpri < PRI_MIN_IDLE)
                    break;
                if (cpu >= mp_maxid) {
                    SCHED_STAT_INC(pickcpu_idle_affinity);
                    return (ts->ts_cpu);
                }
            }
        } else {
            SCHED_STAT_INC(pickcpu_idle_affinity);
            return (ts->ts_cpu);
        }
    }
llc:
    /*
     * Search for the last level cache CPU group in the tree.
     * Skip SMT, identical groups and caches with expired affinity.
     * Interrupt threads affinity is explicit and never expires.
     */
    for (ccg = NULL; cg != NULL; cg = cg->cg_parent) {
        if (cg->cg_flags & CG_FLAG_THREAD)
            continue;
        if (cg->cg_children == 1 || cg->cg_count == 1)
            continue;
        if (cg->cg_level == CG_SHARE_NONE ||
            (!intr && !SCHED_AFFINITY(ts, cg->cg_level)))
            continue;
        ccg = cg;
    }
    /* Found LLC shared by all CPUs, so do a global search. */
    if (ccg == cpu_top)
        ccg = NULL;
    cpu = -1;
    mask = td->td_cpuset->cs_mask;
    pri = td->td_priority;
    /*
     * Try hard to keep interrupts within found LLC.  Search the LLC for
     * the least loaded CPU we can run now.  For NUMA systems it should
     * be within target domain, and it also reduces scheduling overhead.
     */
    if (ccg != NULL && intr) {
        cpu = sched_lowest(ccg, mask, pri, INT_MAX, ts->ts_cpu);
        if (cpu >= 0)
            SCHED_STAT_INC(pickcpu_intrbind);
    } else
    /* Search the LLC for the least loaded idle CPU we can run now. */
    if (ccg != NULL) {
        cpu = sched_lowest(ccg, mask, max(pri, PRI_MAX_TIMESHARE),
            INT_MAX, ts->ts_cpu);
        if (cpu >= 0)
            SCHED_STAT_INC(pickcpu_affinity);
    }
    /* Search globally for the least loaded CPU we can run now. */
    if (cpu < 0) {
        cpu = sched_lowest(cpu_top, mask, pri, INT_MAX, ts->ts_cpu);
        if (cpu >= 0)
            SCHED_STAT_INC(pickcpu_lowest);
    }
    /* Search globally for the least loaded CPU. */
    if (cpu < 0) {
        cpu = sched_lowest(cpu_top, mask, -1, INT_MAX, ts->ts_cpu);
        if (cpu >= 0)
            SCHED_STAT_INC(pickcpu_lowest);
    }
    
    /*
     * Compare the lowest loaded cpu to current cpu.
     */
    tdq = TDQ_CPU(cpu);
    if (THREAD_CAN_SCHED(td, self) && TDQ_SELF()->tdq_lowpri > pri &&
        tdq->tdq_lowpri < PRI_MIN_IDLE &&
        TDQ_SELF()->tdq_load <= tdq->tdq_load + 1) {
        SCHED_STAT_INC(pickcpu_local);
        cpu = self;
    }
    if (cpu != ts->ts_cpu)
        SCHED_STAT_INC(pickcpu_migration);
    return (cpu);
}
```
:::




#### Na jakiej podstawie wyznaczany jest koszt migracji na inny procesor?
Na podstawie topologi procesorów oraz współdzielonych zasobów.


## ZAD 7

#### Co ile czasu uruchamiana jest procedura sched_balance?
Co maksimum balance_tick'ów. [link](http://bxr.su/FreeBSD/sys/kern/sched_ule.c#2418)
:::spoiler [sched_balance](http://bxr.su/FreeBSD/sys/kern/sched_ule.c#sched_balance)
```C
static void
sched_balance(void)
{
    struct tdq *tdq;

    balance_ticks = max(balance_interval / 2, 1) +
        (sched_random() % balance_interval);
    tdq = TDQ_SELF();
    TDQ_UNLOCK(tdq);
    sched_balance_group(cpu_top);
    TDQ_LOCK(tdq);
}
```
:::

::: spoiler [sched_balance_pair](http://bxr.su/FreeBSD/sys/kern/sched_ule.c#sched_balance_pair)
```C
/*
 * Transfer load between two imbalanced thread queues.
 */
static int
sched_balance_pair(struct tdq *high, struct tdq *low)
{
    struct thread *td;
    int cpu;

    tdq_lock_pair(high, low);
    td = NULL;
    /*
     * Transfer a thread from high to low.
     */
    if (high->tdq_transferable != 0 && high->tdq_load > low->tdq_load &&
        (td = tdq_move(high, low)) != NULL) {
        /*
         * In case the target isn't the current cpu notify it of the
         * new load, possibly sending an IPI to force it to reschedule.
         */
        cpu = TDQ_ID(low);
        if (cpu != PCPU_GET(cpuid))
            tdq_notify(low, td);
    }
    tdq_unlock_pair(high, low);
    return (td != NULL);
}

```
:::

#### Ile zadań na raz przenosi procedura tdq_move?
Próbuje przenieść jedno zadanie.
#### Kiedy tdq_notify musi wysłać przerwanie międzyprocesorowe do procesora biorcy?
Jeśli priorytet aktualny jest mniejszy niż nowego wątku i nie jest wątkiem jałowym 