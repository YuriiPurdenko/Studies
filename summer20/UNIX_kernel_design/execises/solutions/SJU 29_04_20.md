# SJU 29/04/20
## ZAD 3
Za pomocą flagi SA_RESTART

The affected system calls
include open(2), read(2), write(2), sendto(2),
recvfrom(2), sendmsg(2) and recvmsg(2) on a communications
channel or a slow device (such as a terminal, but not a
regular file) and during a wait(2) or ioctl(2).

## ZAD 4
## ZAD 5

## ZAD 6
OGARNIĘTE +/-
```C
308void
309sleepq_add(const void *wchan, struct lock_object *lock, const char *wmesg,
310    int flags, int queue)
311{
312    struct sleepqueue_chain *sc;
313    struct sleepqueue *sq;
314    struct thread *td;
315
316    td = curthread;
317    sc = SC_LOOKUP(wchan);    "wpis w naszej hashowanej tablicy"

"prawdzenie poprawności argumentów (mpass) i czy posiadamy odpowiedni mutex"

322

"sprawdzenie czy wgl możemy zasnąć wpp umieraj!"

332
333    /* Look up the sleep queue associated with the wait channel 'wchan'. */
334    sq = sleepq_lookup(wchan);
335
336    /*
337     * If the wait channel does not already have a sleep queue, use
338     * this thread's sleep queue.  Otherwise, insert the current thread
339     * into the sleep queue already in use by this wait channel.
340     */
341    if (sq == NULL) {    "jeśli jesteśmy pierwsi"
342#ifdef INVARIANTS        
343        int i;
344
345        sq = td->td_sleepqueue;

"kasserty"

355        sq->sq_lock = lock;
356#endif

"Sleepqueue profiling nas, aż tak nie interesuje"

365        sq = td->td_sleepqueue;
366        LIST_INSERT_HEAD(&sc->sc_queues, sq, sq_hash); "tworzymy wpis w sc"
367        sq->sq_wchan = wchan;                          "i go konfigurujemy"
368        sq->sq_type = flags & SLEEPQ_TYPE;
369    } else {                                "jeśli nie jesteśmy pierwsi"
                                                "dodajemy nasze sleepqueue"
"Mpassy sprawdzają poprawność"

373        LIST_INSERT_HEAD(&sq->sq_free, td->td_sleepqueue, sq_hash);
374    }

375    thread_lock(td);    "uargumentować dlaczego lock"
376    TAILQ_INSERT_TAIL(&sq->sq_blocked[queue], td, td_slpq);
377    sq->sq_blockedcnt[queue]++;
378    td->td_sleepqueue = NULL;
379    td->td_sqqueue = queue;
380    td->td_wchan = wchan;
381    td->td_wmesg = wmesg;
382    if (flags & SLEEPQ_INTERRUPTIBLE) {
383        td->td_intrval = 0;
384        td->td_flags |= TDF_SINTR;
385    }
386    td->td_flags &= ~TDF_TIMEOUT;
387    thread_unlock(td);
388}
```
```C
817static void
818sleepq_remove_thread(struct sleepqueue *sq, struct thread *td)
819{
820    struct sleepqueue_chain *sc __unused;
821

"mpassy i asserty niech nas nie rozpraszają"

827    sc = SC_LOOKUP(sq->sq_wchan);
828    mtx_assert(&sc->sc_lock, MA_OWNED);

"statically-defined tracing probes nie interesują nas"

832    /* Remove the thread from the queue. */
833    sq->sq_blockedcnt[td->td_sqqueue]--;
834    TAILQ_REMOVE(&sq->sq_blocked[td->td_sqqueue], td, td_slpq);
835
836    /*
837     * Get a sleep queue for this thread.  If this is the last waiter,
838     * use the queue itself and take it out of the chain, otherwise,
839     * remove a queue from the free list.
840     */
841    if (LIST_EMPTY(&sq->sq_free)) {        "jeśli usuneliśmy ostanie sleepqueu"
842        td->td_sleepqueue = sq;
843#ifdef INVARIANTS
844        sq->sq_wchan = NULL;
845#endif

"sleepqueue profiling"

849    } else                                   "jeśli mamy wiele sleepqueue bierzemy pierwsze"
850        td->td_sleepqueue = LIST_FIRST(&sq->sq_free);
851    LIST_REMOVE(td->td_sleepqueue, sq_hash);
852
853    if ((td->td_flags & TDF_TIMEOUT) == 0 && td->td_sleeptimo != 0)
854        /*
855         * We ignore the situation where timeout subsystem was
856         * unable to stop our callout.  The struct thread is
857         * type-stable, the callout will use the correct
858         * memory when running.  The checks of the
859         * td_sleeptimo value in this function and in
860         * sleepq_timeout() ensure that the thread does not
861         * get spurious wakeups, even if the callout was reset
862         * or thread reused.
863         */
864        callout_stop(&td->td_slpcallout);
865
866    td->td_wmesg = NULL;
867    td->td_wchan = NULL;
868    td->td_flags &= ~(TDF_SINTR | TDF_TIMEOUT); "SINTR - sleep is interuptable"

"kernel tracing facility"

872}
```
## ZAD 7
## 1. Implementacja sleepqueue nie wymaga, by z każdym możliwym wchan kojarzyć głowę kolejki uśpionych wątków. Czemu wystarczy, by jądro przypisało po jednym rekordzie sleepqueue do każdego wątku?
Wątek może spać co najwyżej na jednym wchan i w tym celu musi
oddać własne sleepqueue. Zatem w systemie nie potrzeba więcej
sleepqueue niż jest wątków jądra! ~ wykład
```C
struct sleepqueue {
 TAILQ_HEAD(, thread) sq_blocked[2];
 u_int sq_blockedcnt[2]; 
 LIST_ENTRY(sleepqueue) sq_hash;
 LIST_HEAD(, sleepqueue) sq_free;
 void *sq_wchan;
 int sq_type;
};
```

sq_blocked dwa razy, ponieważ mamy dwa rodzaje: (upewnić się)

#define SQ_EXCLUSIVE_QUEUE 0
#define SQ_SHARED_QUEUE 1
## 2. Zauważ, że między wykonaniem procedury sleepq_add i sleepq_wait, która usypia wątek, może dojść do wywłaszczenia wątku. Jak zatem implementacja unika problemu zagubionej pobudki?
Sprawdzamy czy zostało nam zwrócone sleepqueue (w procedurze sleepq_switch, które oddajemy w sleepq_add

## ZAD 8
Pojęcia:
pamięc zadrutowana (wired memory/ wired page) - nie jest obiektem wymiany przez demona stronicowania (pageout demon). Nie powodują page faultów. Stosowane w kernel spacie.
stronnicowalna pamięć (pageable memory) -
Czemu nie można trzymać blokady mutex(9) (ani «MTX_DEF», ani «MTX_SPIN») robiąc dostępy do pamięci stronicowalnej?
Select a repo