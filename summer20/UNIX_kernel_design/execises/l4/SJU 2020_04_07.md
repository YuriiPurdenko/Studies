# SJU 2020/04/07

## Zadanie 1.
A filter routine executes in primary interrupt context
(that is, it does not have its own context). Thus, it cannot block or context switch, and it can use only spin mutexes for synchronization. Due to these
constraints, filter routines are typically used only with devices that require a
nonpreemptive interrupt handler.
A filter routine may either completely handle an interrupt or defer the
computationally expensive work to its associated ithread routine, assuming it
has one. 
Jest to wołane z [procedury obsługi przerwania](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1304).
Logicznie patrząc, `filter routines` siedzą w dolnej połówce.

**kontekst przerwania sprzętowego**- przerwanie nie ma swojego nowego kontekstu (czyli np. stosu), więc wykonuje się w (częściowym, okrojonym) kontekście przerwanego wątku.

Trzeba pamiętać, że podczas działania `filter routine` przerwania są wyłączone, więc jeśli pójdziemy spać to możemy już nie wstać.

## Zadanie 1. (wersja Wiktora)
1. Pojęcia:
    * kontekst przerwania sprzetowego (hard interrupt context)

Krótki opis filtr'a i ithread'a - [bus_setup_intr(9)](https://www.freebsd.org/cgi/man.cgi?query=bus_setup_intr&sektion=9&apropos=0&manpath=FreeBSD+12.1-RELEASE+and+Ports)

### Jakie są zadania procedury «ih_filter» należącej do struktury [intr_handler](http://bxr.su/FreeBSD/sys/sys/interrupt.h#intr_handler) i kto ją woła?

```C
48struct intr_handler {
49    driver_filter_t *ih_filter; /* Filter handler function. */
50    driver_intr_t   *ih_handler;    /* Threaded handler function. */
51    void        *ih_argument;   /* Argument to pass to handlers. */
52    int      ih_flags;
53    char         ih_name[MAXCOMLEN + 1]; /* Name of handler. */
54    struct intr_event *ih_event;    /* Event we are connected to. */
55    int      ih_need;   /* Needs service. */
56    CK_SLIST_ENTRY(intr_handler) ih_next; /* Next handler for this event. */
57    u_char       ih_pri;    /* Priority of this handler. */
58};
```
    time-critical handler that will not execute any potentially
     blocking operation

Na co pozwala filter:
* spin lock	can be used
* wakeup(9) and similar routines can be called.
* Atomic operations from machine/atomic may be used.
* Reads and writes to hardware through bus_space(9) may be used.
* PCI configuration registers may be read and written.
* All other kernel	interfaces cannot be used.

Zadania filtr'a:
* is to simply mask	the interrupt in hardware and allow the
     ithread routine to	read the state from the	hardware and then reenable interrupts.
* filter z tasqueue task - filter acknowledges the interrupts and queues
     the work to the appropriate taskqueue.  Where one has to multiplex	diferent kinds of interrupt sources,	like a network card's transmit and receive paths, this can reduce lock contention and increase performance.

Podsumowując filter - jak sama nazwa wskazuje odsiewa nam, niektóre przerwania, z którymi jest powiązany i powiadamia o tym innych(że przyszło takie przerwanie lub że mają coś do wykonania).

Wołany przez wątek, który znajduje się w dolnej połówce i będzie obsługiwał dane przerwanie?.
[link](https://lists.freebsd.org/pipermail/freebsd-hackers/2017-April/050889.html)

Miejsca w których jest wołany:
[intr_event_handle](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1357)
[intr_event_handle](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1359)

### «filter» wykonuje się w kontekście przerwania sprzętowego (ang. hard interrupt context), czyli przerwanego wątku – co to oznacza?

Oznacza to, że nie ma on własnego kontekstu (czyli np. stosu), więc wykonuje się w (częściowym, okrojonym) kontekście przerwanego wątku.



### Procedura «filter» może korzystać wyłącznie z blokad wirujących – co mogłoby się stać, gdyby znieść to ograniczenie?

    Spin mutexes should be used only when absolutely necessary, 
    e.g. to protect data shared with interrupt filter code
[locking(9)](https://www.freebsd.org/cgi/man.cgi?locking(9))
    
    MTX_SPIN, which disable interrupt
    
    If you have borrowed someone else's state, anything that suspends
    you, suspends them too.  Since this may deadlock, you are not
    allowed to do it at all.
[link](https://lists.freebsd.org/pipermail/freebsd-hackers/2017-April/050894.html)

### Jaki będzie faktyczny priorytet przerwanego wątku? Co stanie się czasem obsługi przerwania?

Skoro chcemy być nieprzerywalni oznacza to, że nasz wątek tymczasowo uzyskuje najwyższy priorytet.



## Zadanie 2.
An ithread routine, unlike a filter routine, executes in its own thread con-
text. You can do whatever you want in an ithread routine, except voluntarily
context switch (that is, sleep) or wait on a condition variable. Because filter
routines are nonpreemptive, most interrupt handlers in FreeBSD are just
ithread routines. `ithread` znajdują się w górnej połówce.

In an	unbounded sleep (often referred to as simply "sleeping") a thread	waits for an external event or for a condition to	become true.

Nie możemy używać środków synchronizacji stosujących sen nieograniczony dlatego, że może przyjść kolejne przerwanie i trzeba będzie je też obsłużyć. W snach ograniczonych jedynym zasobem, który potrzeba to czas CPU, a go zawsze można przydzielić jeśli jest pilne wykonać jakieś zadanie.

## Zadanie 2. (wersja Wiktora)

1. Pojęcia:
    * wątki przerwań - [ithread(9)](http://mdoc.su/f/9/ithread) - Interrupt threads are kernel threads that run a list of handlers when triggered by either a hardware or software	interrupt.
    * sen nieograniczony -  zadanie oczekuje na zdarzenie zewnętrzne, które wydarzy się w niedalekiej przyszłości (intencja programisty jądra)

### Wady uruchamiania procedury obsługi przerwania za pomocą wątków przerwań.

* interrupt threads run at real-time kernel priority

* The interrupt threads currently in FreeBSD are referred to as heavyweight interrupt threads. They are called this because switching to an interrupt thread involves a full context switch. 
[link](https://www.freebsd.org/doc/en_US.ISO8859-1/books/arch-handbook/smp-design.html)
* Brak snu nieprzerywalnego

Pewna optymalizacja do 2. to  lightweight context switches (nie trzeba przełączać VM space'a), ale są z tym pewne problemy.

### Dlaczego wątki przerwań nie mogą przejść w sen nieograniczony?

Ponieważ czekając na zdarzenie zewnętrzne, które może się nigdy nie wydarzyć i np. nie obsłużymy przyszłych interuptów.
## Zadanie 3. (wersja alternatywna)
Funkcje te są wywoływane z głównej funkcji obsługi przerwania http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1304.

Przykład z GPIO na armie(general purpose i/o, czyli kontrola fizycznych pinów) http://bxr.su/FreeBSD/sys/arm/mv/gpio.c#440.
Gdy się zmieni stan na pinie to generowane jest przerwanie.
Kod:
```c=440
error = intr_event_create(&event, (void *)s, 0, pin,
	(void (*)(void *))mv_gpio_intr_mask,
	(void (*)(void *))mv_gpio_intr_unmask,
	(void (*)(void *))mv_gpio_int_ack,
	NULL,
	"gpio%d:", pin);
```

`mv_gpio_intr_mask` - maskuje nam to przerwanie, żeby znów nie przyszło
`mv_gpio_intr_unmask` - maskuje nam to przerwanie, żeby znów nie przyszło
`mv_gpio_intr_ack` - potwierdzamy odebranie interruptu poprzez wpisanie do pina tej samej wartości jaka teraz jest.

Kolejny przykład do coś do obsługi sieci, pewnie karta sieciowa http://bxr.su/FreeBSD/sys/mips/atheros/apb.c#301:

```c=301
error = intr_event_create(&event, (void *)irq, 0, irq,
	apb_mask_irq, apb_unmask_irq,
	NULL, NULL,
	"apb intr%d:", irq);
```

Czyli znów `pre_ithread` maskuje interrupt, a `post_ithread` je odblokowuje.

## Zadanie 3

[`intr_event_create`](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#intr_event_create)

```C=253
int
intr_event_create(struct intr_event **event, void *source, int flags, int irq,
    void (*pre_ithread)(void *), void (*post_ithread)(void *),
    void (*post_filter)(void *), int (*assign_cpu)(void *, int),
    const char *fmt, ...)
{
    struct intr_event *ie;
    va_list ap;

    /* The only valid flag during creation is IE_SOFT. */
    if ((flags & ~IE_SOFT) != 0)
        return (EINVAL);
    ie = malloc(sizeof(struct intr_event), M_ITHREAD, M_WAITOK | M_ZERO);
    ie->ie_source = source;
    ie->ie_pre_ithread = pre_ithread;
    ie->ie_post_ithread = post_ithread;
    ie->ie_post_filter = post_filter;
    ie->ie_assign_cpu = assign_cpu;
    ie->ie_flags = flags;
    ie->ie_irq = irq;
    ie->ie_cpu = NOCPU;
    CK_SLIST_INIT(&ie->ie_handlers);
    mtx_init(&ie->ie_lock, "intr event", NULL, MTX_DEF);

    va_start(ap, fmt);
    vsnprintf(ie->ie_name, sizeof(ie->ie_name), fmt, ap);
    va_end(ap);
    strlcpy(ie->ie_fullname, ie->ie_name, sizeof(ie->ie_fullname));
    mtx_lock(&event_lock);
    TAILQ_INSERT_TAIL(&event_list, ie, ie_list);
    mtx_unlock(&event_lock);
    if (event != NULL)
        *event = ie;
    CTR2(KTR_INTR, "%s: created %s", __func__, ie->ie_name);
    return (0);
}
```

Pytanie: Co robi `malloc` w jądrze??? Spodziewałem się, że będzie tu raczej coś w stylu `kmalloc` aczkolwiek man(9) potwierdza istnienie funkcji analogicznych do libc w jądrze.


```C=109
struct intr_event {
    TAILQ_ENTRY(intr_event) ie_list;
    CK_SLIST_HEAD(, intr_handler) ie_handlers; /* Interrupt handlers. */
    char        ie_name[MAXCOMLEN + 1]; /* Individual event name. */
    char        ie_fullname[MAXCOMLEN + 1];
    struct mtx  ie_lock;
    void        *ie_source; /* Cookie used by MD code. */
    struct intr_thread *ie_thread;  /* Thread we are connected to. */
    void        (*ie_pre_ithread)(void *);
    void        (*ie_post_ithread)(void *);
    void        (*ie_post_filter)(void *);
    int     (*ie_assign_cpu)(void *, int);
    int     ie_flags;
    int     ie_hflags;  /* Cumulative flags of all handlers. */
    int     ie_count;   /* Loop counter. */
    int     ie_warncnt; /* Rate-check interrupt storm warns. */
    struct timeval  ie_warntm;
    int     ie_irq;     /* Physical irq number if !SOFT. */
    int     ie_cpu;     /* CPU this event is bound to. */
    volatile int    ie_phase;   /* Switched to establish a barrier. */
    volatile int    ie_active[2];   /* Filters in ISR context. */
};
```

```
* Describe an interrupt event.  An event holds a list of handlers.
* The 'pre_ithread', 'post_ithread', 'post_filter', and 'assign_cpu'
* hooks are used to invoke MD code for certain operations.
*
* The 'pre_ithread' hook is called when an interrupt thread for
* handlers without filters is scheduled.  It is responsible for
* ensuring that 1) the system won't be swamped with an interrupt
* storm from the associated source while the ithread runs and 2) the
* current CPU is able to receive interrupts from other interrupt
* sources.  The first is usually accomplished by disabling
* level-triggered interrupts until the ithread completes.  The second
* is accomplished on some platforms by acknowledging the interrupt
* via an EOI.
*
* The 'post_ithread' hook is invoked when an ithread finishes.  It is
* responsible for ensuring that the associated interrupt source will
* trigger an interrupt when it is asserted in the future.  Usually
* this is implemented by enabling a level-triggered interrupt that
* was previously disabled via the 'pre_ithread' hook.
*
* The 'post_filter' hook is invoked when a filter handles an
* interrupt.  It is responsible for ensuring that the current CPU is
* able to receive interrupts again.  On some platforms this is done
* by acknowledging the interrupts via an EOI.
*
* The 'assign_cpu' hook is used to bind an interrupt source to a
* specific CPU.  If the interrupt cannot be bound, this function may
* return an error.
*
* Note that device drivers may also use interrupt events to manage
* multiplexing interrupt interrupt handler into handlers for child
* devices.  In that case, the above hooks are not used.  The device
* can create an event for its interrupt resource and register child
* event handlers with that event.  It can then use
* intr_event_execute_handlers() to execute non-filter handlers.
* Currently filter handlers are not supported by this, but that can
* be added by splitting out the filter loop from intr_event_handle()
* if desired.
```

### Przykłady użyc [intr_event_create](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#intr_event_create):

Podczas:
* ustawiania handlera przerwania na armie - [link](http://bxr.su/FreeBSD/sys/arm/arm/intr.c#149)
* ustawienia handlera przerwania softwerowego - [link](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1032)
* ustawienie handlera przerwania hardwerowego na mipsie - [link](http://bxr.su/FreeBSD/sys/mips/mips/intr_machdep.c#174)

### Miejsce wywołania «pre_ithread», «post_ithread» i «post_filter»:

Miejsce wywołania:
* [«pre_ithread»](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1392)
* [«post_ithread»](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1197)
* [«post_filter»](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1395)

Przy obsłudze intr - «pre_ithread» i «post_filter»
1.  Filter (jeśli mamy)
2.  Później pre_ithred (jeśli ithread powstanie) lub post_filter (wpp) lub nic (jeśli wskaźniki na te funkcje == NULL)
3.  Następnie ithread (jeśli mamy)

Wywoływane podczas ithreada - «post_ithread» [link](http://bxr.su/FreeBSD/sys/kern/kern_intr.c#1254)


## Zadanie 4

[`tsleep`](https://www.freebsd.org/cgi/man.cgi?query=tsleep&sektion=9) w [`systm.h`](http://bxr.su/FreeBSD/sys/sys/systm.h#512)

Jest to nakładka na [`_sleep`](http://bxr.su/FreeBSD/sys/kern/kern_synch.c#135) które:
> Suspends the current thread until a wakeup is performed on the specified identifier.

Opis `tsleep`
```
If a thread must wait for an external event, it is put
to sleep by tsleep(), ...
 
chan is an arbitrary address	that uniquely identifies the
event on which the thread is being put to sleep.
 
The parameter priority specifies a new priority for the 
thread as well as some optional flags.
If priority includes the PCATCH flag, pending signals are allowed to
interrupt the sleep, otherwise pending signals are ignored during the
sleep. If PCATCH is set and a signal becomes pending, ERESTART is
returned if the current system call should be restarted if possible,
and EINTR is returned if the system call should be interrupted
by the signal (return EINTR).

The parameter wmesg is a string describing the sleep 
condition for tools like ps(1).
 
The parameter timo specifies a timeout for the sleep.
```

Książka:
```
The decision of whether to use an interruptible sleep depends on
how long the thread may be blocked. Because it is complex to
handle signals in the midst of doing some other operation, 
many sleep requests are not interruptible; that is, a thread 
will not be scheduled to run until the event for which it is
waiting occurs. For example, a thread waiting for disk I/O 
will sleep with signals blocked.

Occasionally, an event that is supposed to occur quickly, such as
a disk I/O, will get held up because of a hardware failure.
Because the thread is sleeping in the kernel with signals blocked,
it will be impervious to any attempts to send it a signal, even a
signal that should cause it to exit unconditionally. The only 
solution to this problem is to change sleep()s on hardware events 
that may hang to be interruptible
```

Problem 1.
Robimy odczyt z NFS (local I/O jest nieprzerywalne). Odczyt dotyczy bazy danych (mamy apkę w php obsługiwaną przez apache). Apache spami sobie procesami php i nagle wszystkie wiszą na bazie danych która próbuje coś zrobić. W optymistycznym przypadku jedynie nie działa nam strona, w gorszym, apache zawali nas tyloma prcoesami, że nie będzie można utworzyć nowego (aby choćby naprawić serwer), jednocześnie wszystkie będą jadły zasoby jak szalone.

Problem 2.
Chcemy zdebugować taki proces który się wywalił. No to ja jak debuguję coś co nagle się zatrzymało to odpalam strace i patrzę co się dzieje. Aby móc robić takie rzeczy używamy `ptrace`. Ale ono jest nieprzerywalne samo w sobie. Dodatkowo `ptrace` wymaga przerwania procesu, który chcemy nadzorować. No i pojawia się pewien istotny problem. Nasz strace zdechł i jest w stanie w którym nie możemy go zabić (no i nigdy nie będziemy już mogli bo żaden syscall nie zakończy się).

Problem 3.
Blokujemy wewnętrzne struktury w jądrze, co może doprowadzić do jakiś niefajnych deadlocków na całym kernelu.

Bonus:
mamy cos takiego, jak TASK_KILLABLE na Linux. Nie można mu zrobić normalnego interrupta, ale możemy zrobić mu killa.

## Zadanie 5

* _tick_ -- 1000 razy na sekundę (generuje przerwanie zegarowe)
* ale mamy oszustwo i jądro zazwyczaj sobie robi to "much less frequently" (bo uznaje, że nie warto to obsługiwać częściej)
* dlaczego oszukujemy? bo jak komputer idzie sobie spać i nie musi obsługiwać przerwanka to zjada mniej prądu (fajne w laptopie)
* `hardclock` to była procedurka, która sobie to obsługiwała
    * z oczywistych powodów musi on działać bardzo szybko (szybciej niż jeden tick) bo zaczniemy gubić czas i będzie bardzo nieprzyjemnie
    * jako, że ma priorytet niczym Królowa Angielska to wszystko inne jest zablokowane na czas jego wykonania -- a co się dzieje jak blokujemy obsługę karty sieciowej? no pakiety nie dochodzą.... a co się dzieje jak nie dochodzą nam pakiety UDP jak oglądamy Barwy Szczęścia? no jesteśmy nieszczęśliwi
* `softclock` no to jak wiemy, że `hardclock` jest jak Królowa Angielska to potrzebujemy czegoś, do czego deleguje się mniej ważne rzeczy, no i tym zajmuje się softclock
* `statclock` 127 razy na sekundę, dla jakiś statystyk systemowych
* `profclock` 8128 razy na sekudnę do profilowania

No i co robi `hardclock`?
* jeśli mamy ustawiony timer wirtualny lub profilowania to dekrementujemy go i jeśli upłynął czas to dostarczamy sygnał (trochę nie po polsku)
* poprawiamy czas dnia o odpowiednią liczbę (względem poprzedniego wywołania timera)
* jeśli nie ma ustawionego `profclock` to wykonujemy jego robotę
* jak wyżej dla `statclock`
* jeśli `softclock` powinien zostać wykonany, to robimy proces z nim `runnable`
* wymusza context switcha (historycznie tak robił)


`statclock`
* po 4 tickach dla procesu robimy ponowne przeliczenie priorytetu
* dalsza statystyka (co robiliśmy w momencie ticka)


`softclock`
* przeliczanie priorytetów (ale scheduler mamy już raz na sekundę)
* timeouty -- informowanie o nich procesów
* retransmisja dropniętych pakietów
* watchdog

mamy coś takiego jak `callout queue` w którą wrzuamy co się ma stać jak przyjdzie timeout (obrazek był na wykładzie) -- mamy 200 takich kolejek (po jednej na tick, umiemy więc reprezentować czas od teraz do teraz + 199)

kiedy robimy`hardclock` to `teraz++` (odnosząc się do kolejek), jeśli kolejka z `teraz` nie jest pusta, to będziemy zapuszczać `softclock` który zajmuje się interpretacją zawartości kolejki

oczywiście w naszym wpisie w kolejce pamiętamy kiedy przyjdzie `teraz`, więc jak chcemy wrzucić się do czasu `teraz + n` to liczymy `teraz + n mod 200` (jeśli umiem matematykę, ale wiadomo o co chodzi) i wrzucamy też do kolejki informację o tym jaki tick nas interesuje (jak przyjdzie zły tick to po porstu będziemy nadal czekać w tej kolejce, a jak przyjdzie interesujący nas tick to wywalimy się z kolejki -- teraz zastanawiam się czy nazwanie tego kolejką jest sensowne?)


```C=136
int
hardclockintr(void)
{
    sbintime_t now;
    struct pcpu_state *state;
    int done;

    if (doconfigtimer() || busy)
        return (FILTER_HANDLED);
    state = DPCPU_PTR(timerstate);
    now = state->now;
    CTR3(KTR_SPARE2, "ipi  at %d:    now  %d.%08x",
        curcpu, (int)(now >> 32), (u_int)(now & 0xffffffff));
    done = handleevents(now, 0);
    return (done ? FILTER_HANDLED : FILTER_STRAY);
}
```

`doconfigtimer` -- Reconfigure specified per-CPU timer on other CPU. Called from IPI handler. (na podstawie action z pcpu_state)

```C=113
struct pcpu_state {
    struct mtx  et_hw_mtx;  /* Per-CPU timer mutex. */
    u_int       action;     /* Reconfiguration requests. */
    u_int       handle;     /* Immediate handle resuests. */
    sbintime_t  now;        /* Last tick time. */
    sbintime_t  nextevent;  /* Next scheduled event on this CPU. */
    sbintime_t  nexttick;   /* Next timer tick time. */
    sbintime_t  nexthard;   /* Next hardclock() event. */
    sbintime_t  nextstat;   /* Next statclock() event. */
    sbintime_t  nextprof;   /* Next profclock() event. */
    sbintime_t  nextcall;   /* Next callout event. */
    sbintime_t  nextcallopt;    /* Next optional callout event. */
    int     ipi;        /* This CPU needs IPI. */
    int     idle;       /* This CPU is in idle mode. */
};
```

Pytanie, dlaczego `typedef __int64_t   sbintime_t;`? `__int64_t` to w tym przypadku typedef na long long, dlaczego nie używamy po prostu nazewnictwa `int64_t`? 


[`handleevents`](http://bxr.su/FreeBSD/sys/kern/kern_clocksource.c#handleevents)
```C=155
static int
handleevents(sbintime_t now, int fake)
{
    sbintime_t t, *hct;
    struct trapframe *frame;
    struct pcpu_state *state;
    int usermode;
    int done, runs;

    CTR3(KTR_SPARE2, "handle at %d:  now  %d.%08x",
        curcpu, (int)(now >> 32), (u_int)(now & 0xffffffff));
    done = 0;
    if (fake) {
        frame = NULL;
        usermode = 0;
    } else {
        frame = curthread->td_intr_frame;
        usermode = TRAPF_USERMODE(frame);
    }

    state = DPCPU_PTR(timerstate);

    runs = 0;
    while (now >= state->nexthard) {
        state->nexthard += tick_sbt;
        runs++;
    }
    if (runs) {
        hct = DPCPU_PTR(hardclocktime);
        *hct = state->nexthard - tick_sbt;
        if (fake < 2) {
            hardclock(runs, usermode);
            done = 1;
        }
    }
    runs = 0;
    while (now >= state->nextstat) {
        state->nextstat += statperiod;
        runs++;
    }
    if (runs && fake < 2) {
        statclock(runs, usermode);
        done = 1;
    }
    if (profiling) {
        runs = 0;
        while (now >= state->nextprof) {
            state->nextprof += profperiod;
            runs++;
        }
        if (runs && !fake) {
            profclock(runs, usermode, TRAPF_PC(frame));
            done = 1;
        }
    } else
        state->nextprof = state->nextstat;
    if (now >= state->nextcallopt || now >= state->nextcall) {
        state->nextcall = state->nextcallopt = SBT_MAX;
        callout_process(now);
    }

    t = getnextcpuevent(0);
    ET_HW_LOCK(state);
    if (!busy) {
        state->idle = 0;
        state->nextevent = t;
        loadtimer(now, (fake == 2) &&
            (timer->et_flags & ET_FLAGS_PERCPU));
    }
    ET_HW_UNLOCK(state);
    return (done);
}
```

```C=457
void
hardclock(int cnt, int usermode)
{
    struct pstats *pstats;
    struct thread *td = curthread;
    struct proc *p = td->td_proc;
    int *t = DPCPU_PTR(pcputicks);
    int global, i, newticks;

    /*
     * Update per-CPU and possibly global ticks values.
     */
    *t += cnt;
    global = ticks;
    do {
        newticks = *t - global;
        if (newticks <= 0) {
            if (newticks < -1)
                *t = global - 1;
            newticks = 0;
            break;
        }
    } while (!atomic_fcmpset_int(&ticks, &global, *t));

    /*
     * Run current process's virtual and profile time, as needed.
     */
    pstats = p->p_stats;
    if (__predict_false(
        timevalisset(&pstats->p_timer[ITIMER_VIRTUAL].it_value) ||
        timevalisset(&pstats->p_timer[ITIMER_PROF].it_value)))
        hardclock_itimer(td, pstats, cnt, usermode);

#ifdef  HWPMC_HOOKS
    if (PMC_CPU_HAS_SAMPLES(PCPU_GET(cpuid)))
        PMC_CALL_HOOK_UNLOCKED(curthread, PMC_FN_DO_SAMPLES, NULL);
    if (td->td_intr_frame != NULL)
        PMC_SOFT_CALL_TF( , , clock, hard, td->td_intr_frame);
#endif
    /* We are in charge to handle this tick duty. */
    if (newticks > 0) {
        tc_ticktock(newticks);
#ifdef DEVICE_POLLING
        /* Dangerous and no need to call these things concurrently. */
        if (atomic_cmpset_acq_int(&devpoll_run, 0, 1)) {
            /* This is very short and quick. */
            hardclock_device_poll();
            atomic_store_rel_int(&devpoll_run, 0);
        }
#endif /* DEVICE_POLLING */
        if (watchdog_enabled > 0) {
            i = atomic_fetchadd_int(&watchdog_ticks, -newticks);
            if (i > 0 && i <= newticks)
                watchdog_fire();
        }
    }
    if (curcpu == CPU_FIRST())
        cpu_tick_calibration();
    if (__predict_false(DPCPU_GET(epoch_cb_count)))
        GROUPTASK_ENQUEUE(DPCPU_PTR(epoch_cb_task));
}
```

```C=231
static sbintime_t
getnextcpuevent(int idle)
{
    sbintime_t event;
    struct pcpu_state *state;
    u_int hardfreq;

    state = DPCPU_PTR(timerstate);
    /* Handle hardclock() events, skipping some if CPU is idle. */
    event = state->nexthard;
    if (idle) {
        hardfreq = (u_int)hz / 2;
        if (tc_min_ticktock_freq > 2
#ifdef SMP
            && curcpu == CPU_FIRST()
#endif
            )
            hardfreq = hz / tc_min_ticktock_freq;
        if (hardfreq > 1)
            event += tick_sbt * (hardfreq - 1);
    }
    /* Handle callout events. */
    if (event > state->nextcall)
        event = state->nextcall;
    if (!idle) { /* If CPU is active - handle other types of events. */
        if (event > state->nextstat)
            event = state->nextstat;
        if (profiling && event > state->nextprof)
            event = state->nextprof;
    }
    return (event);
}
```

* `trapframe` ze 159 linijki to jest po prostu kontekst CPU
* `usermode` rozumiem, że tutaj trzymamy, czy jesteśmy w usermode
* w pętli while w 178 sprawdzamy, czy teraźniejszość przekroczyła czas hardclocka, jeśli tak, to poprawiamy czas następnego hardlocka i zwiększamy licznik, ile hardlocków się wykonało
* jeśli wykonaliśmy tick, to robimy `hardclocka`
    * omówiliśmy już wyżej co robi zgodnie z książką
    * robimy update liczby ticków
    * jeśli mamy ustawiony timer virtual lub profile to liczymy jakieś tam statystyki
    * potem robimy watchdoga jeśli trzeba
    * i kalibrujemy czas
* to samo powtarzamy dla statclocka
* i to samo dla profclocka
* `getnextcpuevent`
    * Schedule binuptime of the next event on current CPU.
    * generalnie liczymy według jakiś ustalonych reguł następny event
* `ET_HW_LOCK` pod spodem to spinlock
* jeśli nie jesteśmy busy to będziemy chcieli być idle